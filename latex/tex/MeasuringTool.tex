\chapter{Measuring Tool}
A critical part of performance testing is to ensure as few variables as possible change during each run of the experiment. This generates more consistent results, and allows easier comparison between test runs.\\
In a typical scientific experiment setup, the variables are separated into dependent, independent, and controlled variables. The dependent variables for this testing are of course the throughput and latency numbers that result from performance benchmarking, as well as the CPU and memory usage of the applications during the test runs. For independent variables, the implementation of the application: in Node.js or Java. The exact same tests are running against the two implementations. Besides these variables, everything else is controlled and kept static, for example, applications are deployed to the same cloud landscape to avoid possible falsified  results from different network latencies. \\


\section{Average response time and throughput}
The average response time takes into consideration every round trip.The resulting metric is a reflection of the speed of the web application being tested – the best indicator of how the server is performing from the users’ perspective. The average response time includes the delivery of all resource being used. Thus, the average will be significantly affected by any slow components.\\
In the thesis response time is measured in three different places as you can see from figure \ref{measure-rt}. The first measuring is done by load generator which records the true end-to-end time and throughput. The second checkpoint is the response time retrieved from Logstash which present the round trip from router. Last measuring spot is inside server itself. It reflects the round trip of a query in database. The end-to-end measuring result is used in the final performance analysis while the others serve as tool to determine where is the bottleneck of the performance test is. Since the requests sent from the load generator contains a unique correlation in its header, it is possible to track one request in all the measuring positions. \\

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{measure-rt}
	\caption{Measure response time three different places}
	\label{measure-rt}
\end{figure}

Throughput is the measurement of bandwidth consumed during the test. It shows how much data is flowing back and forth from servers. The requests made to the server in the thesis do not consume data of any significant size, such as images. Therefore the throughput would directly reflect successfully handled amount of requests during the load testing. \\
\subsection{Recording with Load Generator and its limitations}
 In chapter \ref{load generator}, it is discussed how the load generator drives loads. It carries another duty to record the end-to-end response time for each request. Together with response time it also stores the correlation id and start time for each request. The data is first saved in an array and insert into database at the end of load generating. \\
 However, this information is not enough. It would also be great to know the stored result is resulted from which test settings, like how many application instances or how many parallel requests are sent. Therefore these meta information is given to the load generator and saved along with response time. Since the load generator in this thesis is only a worker, it doesn't provide any API to call with given parameters. All the information external from the generator has to be given as start command. However, in Cloud Foundry one application's start command is defined when it is pushed. This means the generator has to be pushed anew to the Cloud Foundry every time the parameter is changed. A small shell script is written to fulfill the task of pushing. \\
 
 It is easy to scale load generator according to what one needs. On the other hand, it also means the generator has to stay stateless, which results in certain amount of manual work. For example, the same test settings may be carried out in several rounds. The result of different rounds should be saved to compare with each other. Making \textit{testround }a automatically incremented data type is what first comes to mind. Yet it can't be defined like that when there are more than one instance of the generator running. This parameter is hence manually given for every new round of test.\\
 
\subsection{Retrieving data from Logstash and its limitations}
Application involves multiple components to accomplish one little task, for example application server, database, router and so on. Performance test can very easily hit limit of one of the components and converting the test of application into test of a router or database. On account of avoiding such cases, finding and ruling out the bottleneck of all the components are carried out. \\
Network is one of the major causes of bottleneck. Is the router capable of taking in so many requests? The best way is to get the response time from router. Although router is not accessible as a component to the developers, \ac{ELK} \citep{ELK} is integrated into Cloud Foundry at SAP. Router response time is logged as default for every request. The logs produced in the application are saved in Logstash\citep{Logstash} and visualized in Kibana \citep{Kibana}. \\ 
However, in order to compare the router response time with end-to-end response time, just reading the results from visualization in Kibana is not enough. To investigate what causes an exceedingly long response time, one has to seek out the precise request and do the comparison. Kibana's visualization is pretty but more convenient would be directly comparing the figures from Logstash. To retrieve the results, a script is written. It sends a json query to the logstash and then parse the query results and sort out the response time logged by router. Following that the statistics are stored into a database.\\
Of course, the result from Logstash can be very large and takes some time. More strangely the logs appeared to be incomplete. Especially when the load is large. Only ten percent of the requests are retrieved from Logstash. After ruling out there is anything wrong with the application that retrieves the result, it is observed that the logs are always retrieved as bundles of 1000 requests which can be clearly seen from visualization in Kibana. After inquiring the colleagues responsible for ELK on Cloud Foundry,  it turns out there is quota for logs. They don't come unlimited. One can only get a certain total of logs preserved per hour or per day.\\
In spite of incomplete information from Logstash, the comparison from the retrieved data shows the router has no performance bottleneck, at least not at the scale this thesis is aiming for. This leads to the realization of the HAProxy limitation discussed in chapter \ref{haproxy}. 

  \subsection{Recording data inside the application and its limitations}
This would be a very simple task if there is no log limit in Logstash: just log the response time recorded in application and retrieve it from Logstash. With the restriction present, the data has to be saved in database. To elevate the performance of saving such large amount of entries, measures have to be taken: using batch in Java and manipulating array to realize a bulk insert in node.js. In this thesis, the response time and correlation id are saved in an array for all the requests. Another endpoint is defined inside the application to transfer the statistics in array into database.\\
Looking into the response time from database also helps to discover where the bottleneck of database starts. For example, when testing locally, up to a certain number of parallel requests from load generator, the throughput of the application no longer increases while the average response time goes up. Comparing the response time from database, there is an exact analog from peak of end-to-end response time to the peak in the response time from database.The slower requests also require more time to get database connection. \\
Another thing to be taken into consideration is the memory consumption will grow infinitely if one does not transfer recorded data to database. As said above, the information obtained from the application help to identify the efficiency of database. After the determination of limitation, one no longer needs to analyze the data,  consequently forgets to call the endpoint and transfer the data to database. As a result, the array will accumulate, grow into a considerable size and eventually cause out-of-memory. For example, correlation id is saved as 36-letter \textit{string} which consumes 36 * 2 byte memory. Response time is saved as \textit{long} which takes 16 byte. Putting them together, a request needs 88 byte memory to store the response information. If one round of load test generates 100000 requests. it will result in occupying up to 8 MB memory. A node application as a whole only needs maximum 100 MB to run. Therefore a switch should be built inside the application to turn off recording the data or there should be a central operational endpoint to clean up the array before each load testing. 
\section{CPU and Memory consumption}
In chapter \ref{cpu limitation}, it is described how Cloud Foundry allocate its computing resource. In this thesis, tests are conducted on different days and sometimes it is noticed some out of ordinary fluctuations which can be accounted for by a reallocation of computing resource. Nevertheless, CPU and memory consumption are gathered as key metrics since they are directly related to todays cloud pricing mechanism.
\subsection{Cloud Foundry CLI and its limitations}
Since we have no os-level-access to the direct virtual machine in Cloud Foundry, we can not investigate the node. However, the Cloud Foundry command line interface provides simple command \textit{cf app <app-name>} to check the metrics. However, it is extremely tedious and inconvenient to require for the information from command line. Luckily there is a plugin, \textit{cf statistics} \citep{cfstatistics}, which deliver real-time metrics and statistics data. This plugin displays a terminal dashboard showing current app usage metrics/statistics as shown in graph. It can also stream these metrics as JSON formatted output to stdout. It is decided to use the plugin in the thesis. \\
\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{cf-statistics}
	\caption{cf statistics display}
	\label{cf-statistics}
\end{figure}
Although this tool is better than the command line, it still requires manual operation. The data gathered can not be stored into database along with other information. After all what the plugin does is only request the API of Cloud Controller  \citep{cloudcontroller} from Cloud Foundry and gather them together. In the long run it would be advised to write one's own application which fetches the information from cloud controller's rest API as part pf the load testing tool. 
\subsection{Memory consumption}
The memory has double meaning in cloud foundry. One can assign a certain amount of max memory to the application which also decides the computing resource an application can get. However, the application doesn't necessarily consume that much. How much memory does an application need to run? It is known, at some point, when the heap reaches its maximum capacity, a full garbage collection will occur, which will bring down the size of the heap memory. Then it will start to grow again and the cycle should continue as long as the application is running. An application with no memory leaks should continue this cycle until the application is stopped. \\
For apps deployed on Cloud Foundry, one way to find out the actual memory to run the application is to let it run under load until the first full garbage collection occurs. The total used memory of the container will continue to grow until this first garbage collection occurs. After that, the memory utilization of the container will stabilize and will not grow any more with sustained load. Figure \ref{memory} shows how the load test is conducted to find out how much memory the application needs to run. 

\begin{figure}[h]
	\centering
	\includegraphics[width=12cm]{memory}
	\caption{Find out the memory Java and node.js applications need }
	\label{memory}
\end{figure}

\section{Access data from backing service}
In the thesis, raw data instead of aggregated is collected and saved in database in Cloud Foundry.\\
Toad extension for eclipse \citep{toad} is used in the thesis to connect to database and query data. It has no problem connecting to local PostgreSQL, as long as information such as hostname, user, password etc. are provided. Run the command \textit{cf env <application-name>} in Cloud Foundry, one can find a detailed information regarding backing service. For PostgreSQL, exactly the information one needs to establish connection locally are all listed. It seems to be only straightforward to get into the database. However, TCP connection directly to the postgresql back-end service in Cloud Foundry is not possible as the database resides inside the Cloud's subnetwork.\\
Cloud Foundry has provided a solution. It has enabled SSH access to the services in Diego cell \citep{SSH}}. However, if one is behind a cooperate proxy, for example, SAP proxy, the SSH connection cannot be established. \\
Finally, Chisel \citep{chisel} comes to rescue. It is an HTTP client and server which acts as a TCP proxy written in Go. It is an application to be deployed to Cloud Foundry and binded to the target backing service. By starting the application, it maps TCP endpoits of backing services to local workstation and ready to be connected from the toad extension. 

