\chapter{Conclusion}
The aim of the thesis is to compare the performance of Java and Node.js with the focus on SAP use case in Cloud Foundry. The example applications are of minimum complexity and functionality. The consumption of resources are also kept at a low level. Still, both technologies have reached 20\% of average requests handling of Google.com\citep{Google}. This is a quite good and firm performance for SAP business scenario. The CPU usage would rarely reach 100\% before a limitation in the database or router surfaces first. Of course, the application should be properly optimized first and have an efficient CPU usage.\\
The Node.js application has demonstrated a very high utilization of available CPU and memory efficiency, which also makes it suitable for gaining more performance through horizontal scaling. This also have some implications for developers regarding component design. If the cloud application needs to be horizontally scaled up or down at any moment according to the load condition, the components should be designed to be as stateless as possible.\\
Java exhibits a very good CPU efficiency. If the cloud provider charges the cost according to consumed CPU resources instead of reserved CPU total, Java definitely offers a better performance gain. However, if it is not the case, a deep investigation should be conducted into the CPU utilization of the application. If Java can efficiently consume all available CPU power, it offers a great vertical scalability. Despite of the fact that one Java instance consumes more memory, if it can make good use of 64-core system, it would outperform 64 small Node.js instances in terms of memory and CPU. As for horizontal scaling for an optimized Java application, it will achieve possibly the same computing capability but needs a much higher memory consumption. \\
However, no matter Java or Node.js, the scaling competence goes beyond application itself in context of cloud. In the thesis, we have faced a bottleneck imposed from HA-Proxy before we even scale the application at all. This limitation can only be work around at the application level with reusing established connections. There is nothing one can do at the infrastructure level which would mean to rebuild the system since HA-proxy is not built scalable. In comparison, the scaling of Gorouter is done in one day and has been operating perfectly ever since. There are even more to the scaling in cloud: the VMs or container, the database... Every scaling also puts demand on operation and monitoring. For example, high load could cause a defect in monitoring if it is not built to cope with a sudden large amount of reading and writing data entries. It will trigger false alarms and result in false evaluation of cloud platform health. 